import requests
from bs4 import BeautifulSoup
import pandas as pd
from io import StringIO
import time

SCHOOLS = [
"Abilene Christian",
"Air Force",
"Akron",
"Alabama",
"Alabama A&M",
"Alabama State",
"Albany (NY)",
"Alcorn State",
"American",
"Appalachian State",
"Arizona",
"Arizona State",
"Arkansas",
"Arkansas State",
"Arkansas-Pine Bluff",
"Army",
"Auburn",
"Austin Peay",
"Ball State",
"Baylor",
"Bellarmine",
"Belmont",
"Bethune-Cookman",
"Binghamton",
"Boise State",
"Boston College",
"Boston University",
"Bowling Green State",
"Bradley",
"Brigham Young",
"Brown",
"Bryant",
"Bucknell",
"Buffalo",
"Butler",
"Cal Poly",
"Cal State Bakersfield",
"Cal State Fullerton",
"Cal State Northridge",
"California",
"California Baptist",
"Campbell",
"Canisius",
"Central Arkansas",
"Central Connecticut State",
"Central Florida",
"Central Michigan",
"Charleston Southern",
"Charlotte",
"Chattanooga",
"Chicago State",
"Cincinnati",
"Clemson",
"Cleveland State",
"Coastal Carolina",
"Colgate",
"College of Charleston",
"Colorado",
"Colorado State",
"Columbia",
"Connecticut",
"Coppin State",
"Cornell",
"Creighton",
"Dartmouth",
"Davidson",
"Dayton",
"Delaware",
"Delaware State",
"Denver",
"DePaul",
"Detroit Mercy",
"Drake",
"Drexel",
"Duke",
"Duquesne",
"East Carolina",
"East Tennessee State",
"Eastern Illinois",
"Eastern Kentucky",
"Eastern Michigan",
"Eastern Washington",
"Elon",
"Evansville",
"Fairfield",
"Fairleigh Dickinson",
"Florida",
"Florida A&M",
"Florida Atlantic",
"Florida Gulf Coast",
"Florida International",
"Florida State",
"Fordham",
"Fresno State",
"Furman",
"Gardner-Webb",
"George Mason",
"George Washington",
"Georgetown",
"Georgia",
"Georgia Southern",
"Georgia State",
"Georgia Tech",
"Gonzaga",
"Grambling",
"Grand Canyon",
"Green Bay",
"Hampton",
"Hartford",
"Harvard",
"Hawaii",
"High Point",
"Hofstra",
"Holy Cross",
"Houston",
"Houston Christian",
"Howard",
"Idaho",
"Idaho State",
"Illinois",
"Illinois State",
"Illinois-Chicago",
"Incarnate Word",
"Indiana",
"Indiana State",
"Iona",
"Iowa",
"Iowa State",
"IUPUI",
"Jackson State",
"Jacksonville",
"Jacksonville State",
"James Madison",
"Kansas",
"Kansas City",
"Kansas State",
"Kennesaw State",
"Kent State",
"Kentucky",
"La Salle",
"Lafayette",
"Lamar",
"Lehigh",
"Liberty",
"Lindenwood",
"Lipscomb",
"Little Rock",
"Long Beach State",
"Long Island University",
"Longwood",
"Louisiana",
"Louisiana State",
"Louisiana Tech",
"Louisiana-Monroe",
"Louisville",
"Loyola (IL)",
"Loyola (MD)",
"Loyola Marymount",
"Maine",
"Manhattan",
"Marist",
"Marquette",
"Marshall",
"Maryland",
"Maryland-Baltimore County",
"Maryland-Eastern Shore",
"Massachusetts",
"Massachusetts-Lowell",
"McNeese State",
"Memphis",
"Mercer",
"Merrimack",
"Miami (FL)",
"Miami (OH)",
"Michigan",
"Michigan State",
"Middle Tennessee",
"Milwaukee",
"Minnesota",
"Mississippi",
"Mississippi State",
"Mississippi Valley State",
"Missouri",
"Missouri State",
"Monmouth",
"Montana",
"Montana State",
"Morehead State",
"Morgan State",
"Mount St. Mary's",
"Murray State",
"Navy",
"NC State",
"Nebraska",
"Nevada",
"Nevada-Las Vegas",
"New Hampshire",
"New Mexico",
"New Mexico State",
"New Orleans",
"Niagara",
"Nicholls State",
"NJIT",
"Norfolk State",
"North Alabama",
"North Carolina",
"North Carolina A&T",
"North Carolina Central",
"North Dakota",
"North Dakota State",
"North Florida",
"North Texas",
"Northeastern",
"Northern Arizona",
"Northern Colorado",
"Northern Illinois",
"Northern Iowa",
"Northern Kentucky",
"Northwestern",
"Northwestern State",
"Notre Dame",
"Oakland",
"Ohio",
"Ohio State",
"Oklahoma",
"Oklahoma State",
"Old Dominion",
"Omaha",
"Oral Roberts",
"Oregon",
"Oregon State",
"Pacific",
"Penn State",
"Pennsylvania",
"Pepperdine",
"Pittsburgh",
"Portland",
"Portland State",
"Prairie View",
"Presbyterian",
"Princeton",
"Providence",
"Purdue",
"Purdue Fort Wayne",
"Queens (NC)",
"Quinnipiac",
"Radford",
"Rhode Island",
"Rice",
"Richmond",
"Rider",
"Robert Morris",
"Rutgers",
"Sacramento State",
"Sacred Heart",
"Saint Francis (PA)",
"Saint Joseph's",
"Saint Louis",
"Saint Mary's (CA)",
"Saint Peter's",
"Sam Houston State",
"Samford",
"San Diego",
"San Diego State",
"San Francisco",
"San Jose State",
"Santa Clara",
"Seattle",
"Seton Hall",
"Siena",
"South Alabama",
"South Carolina",
"South Carolina State",
"South Carolina Upstate",
"South Dakota",
"South Dakota State",
"South Florida",
"Southeast Missouri State",
"Southeastern Louisiana",
"Southern",
"Southern California",
"Southern Illinois",
"SIU Edwardsville",
"Southern Indiana",
"Southern Methodist",
"Southern Mississippi",
"Southern Utah",
"St. Bonaventure",
"St. Francis (NY)",
"St. John's (NY)",
"St. Thomas (MN)",
"Stanford",
"Stephen F. Austin",
"Stetson",
"Stonehill",
"Stony Brook",
"Syracuse",
"Tarleton State",
"TCU",
"Temple",
"Tennessee",
"Tennessee State",
"Tennessee Tech",
"Tennessee-Martin",
"Texas",
"Texas A&M",
"Texas A&M-Commerce",
"Texas A&M-Corpus Christi",
"Texas Southern",
"Texas State",
"Texas Tech",
"Texas-Rio Grande Valley",
"The Citadel",
"Toledo",
"Towson",
"Troy",
"Tulane",
"Tulsa",
"UAB",
"UC Davis",
"UC Irvine",
"UC Riverside",
"UC San Diego",
"UC Santa Barbara",
"UCLA",
"UNC Asheville",
"UNC Greensboro",
"UNC Wilmington",
"UT Arlington",
"Utah",
"Utah State",
"Utah Tech",
"Utah Valley",
"UTEP",
"UTSA",
"Valparaiso",
"Vanderbilt",
"Vermont",
"Villanova",
"Virginia",
"Virginia Commonwealth",
"VMI",
"Virginia Tech",
"Wagner",
"Wake Forest",
"Washington",
"Washington State",
"Weber State",
"West Virginia",
"Western Carolina",
"Western Illinois",
"Western Kentucky",
"Western Michigan",
"Wichita State",
"William & Mary",
"Winthrop",
"Wisconsin",
"Wofford",
"Wright State",
"Wyoming",
"Xavier",
"Yale",
"Youngstown State"
]

base_url = "https://www.sports-reference.com/cbb/schools/"
urls = []

def format_school_name(school):
    formatted_school = school.replace('&', '').replace("'", "").replace(".", "")
    formatted_school = formatted_school.lower().replace(' ', '-')
    formatted_school = formatted_school.replace('(', '').replace(')', '').replace('--', '-')
    return formatted_school

exception_dict = {
    "Houston Christian": "houston-baptist",
    "Kansas City": "missouri-kansas-city",
    "Little Rock": "arkansas-little-rock",
    "Louisiana": "louisiana-lafayette",
    "Purdue Fort Wayne": "ipfw",
    "Texas-Rio Grande Valley": "texas-pan-american",
    "The Citadel": "citadel",
    "UTSA": "texas-san-antonio",
    "UTEP": "texas-el-paso",
    "Utah Tech": "dixie-state",
    "VMI": "virginia-military-institute",
    "UT Arlington": "texas-arlington",
    "UNC Wilmington": "north-carolina-wilmington",
    "UNC Greensboro": "north-carolina-greensboro",
    "UNC Asheville": "north-carolina-asheville",
    "UC Santa Barbara": "california-santa-barbara",
    "UC San Diego": "california-san-diego",
    "UC Riverside": "california-riverside",
    "UC Irvine": "california-irvine",
    "UC Davis": "california-davis",
    "UAB": "alabama-birmingham",
    "TCU": "texas-christian",
    "SIU Edwardsville": "southern-illinois-edwardsville",
    "Omaha": "nebraska-omaha",
    "NC State": "north-carolina-state"
}

urls = [f"{base_url}{exception_dict.get(school, format_school_name(school))}/men/2023.html" for school in SCHOOLS]

dfs = []  

team_counter = 1

for idx, url in enumerate(urls, 1):
    print(f"Processing {idx}/{len(urls)}: {SCHOOLS[idx-1]}...")
    response = requests.get(url)
    
    if response.status_code != 200:
        print(f"Failed to retrieve data for {SCHOOLS[idx-1]}")
        continue
    
    soup = BeautifulSoup(response.content, 'html.parser')

    per_game_table = soup.find('table', {'id': 'per_game'})
    if not per_game_table:
        print(f"Failed to find per_game table for {SCHOOLS[idx-1]}")
        continue
    df_per_game = pd.read_html(StringIO(str(per_game_table)))[0]
    df_per_game.drop('Rk', axis=1, inplace=True)

    roster_table = soup.find('table', {'id': 'roster'})
    if not roster_table:
        print(f"Failed to find roster table for {SCHOOLS[idx-1]}")
        continue
    df_roster = pd.read_html(StringIO(str(roster_table)))[0]
    df_roster = df_roster[['#', 'Player', 'Class', 'Pos', 'Height', 'Weight']]
    
    advanced_table = soup.find('table', {'id': 'advanced'})
    if not advanced_table:
        print(f"Failed to find advanced_sh table for {SCHOOLS[idx-1]}")
        continue
    df_advanced = pd.read_html(StringIO(str(advanced_table)))[0]
    df_advanced.drop(['Rk', 'G', 'GS', 'MP','Unnamed: 24','Unnamed: 19', 'PProd'], axis=1, inplace=True)

    merged_df = pd.merge(df_roster, df_per_game, on='Player')
    merged_df = pd.merge(merged_df, df_advanced, on = 'Player')

    try:
        merged_df.insert(0, 'School', SCHOOLS[idx-1])
    except IndexError:
        print(f"IndexError at index {idx-1}. Length of SCHOOLS: {len(SCHOOLS)}")

    merged_df.rename(columns={'#': 'Number'}, inplace=True)

    merged_df['Team Counter'] = team_counter
    team_counter += 1 

    already_in_percentage = {"ORB%", "DRB%", "TRB%", "AST%", "STL%", "BLK%", "TOV%", "USG%"}
    percent_columns = [col for col in merged_df.columns if col.endswith('%') and col not in already_in_percentage]
    for col in percent_columns:
        merged_df[col] = (merged_df[col] * 100).round(2)
    
    dfs.append(merged_df)

    time.sleep(5)

final_df = pd.concat(dfs, ignore_index=True)
final_df.to_csv('all_schools_2023_combined_stats.csv', index=False)
